---

title: Discussion Guide: More than a Glitch
date: 2025-01-22
tags:
- books

---

A guide with discussion prompts for [Meredeith Broussard's](https://meredithbroussard.com/) [More than a Glitch: Confronting Race, Gender, and Ability Bias in Tech](https://mitpress.mit.edu/9780262548328/more-than-a-glitch/).

I run the engineering book club at my current company, [Attentive](https://www.attentive.com/). For the pace of our book club, we committed to reading 2 chapters every 2 weeks. I personally appreciate having multiple discussions over time, I find I better retain content that way. These are the exact discussion prompts I used over the few months of reading the book, so they're colored by my personal experience and the current culture at Attentive. All prompts are wholly my own and are free to use by all.

## Chapter 1

- Much of the introduction is centered around the word “technochauvinism” and some real-world examples of it. What does the word mean to you, in your own words?

## Chapter 2

- As technologists, do you agree with the author’s explanation of artificial intelligence and machine learning? Do you think there were any consequential details missed?
  - Do you have any ML examples you like to use when talking with non-technologists?
- Do you agree or disagree with this sentence from the book: “whoever owns the [machine learning] model has an enormous amount of power”?
- What do you think are good and just uses for machine learning?

## Chapter 3

- The author tells a story about [Robert Williams](https://www.aclumich.org/en/press-releases/farmington-hills-father-sues-detroit-police-department-wrongful-arrest-based-faulty "https://www.aclumich.org/en/press-releases/farmington-hills-father-sues-detroit-police-department-wrongful-arrest-based-faulty"), a southeast Michigan man who was arrested based on a low-quality surveillance video screenshot and error-prone facial recognition technology (FRT). Many people had the chance to question the algorithm’s “answer” but didn’t. Do you have any personal examples of a decision chain failing you, or regrets of participating in a faulty one?
- Companies that create facial recognition technology (FRT) are incentivized to continually push the adoption of the technology, mostly by government agencies. Customers are incentivized to use the technology as much as possible to justify the cost. Can these incentives ever be aligned to the goal of fair and just policing?
- The lack of audit trails and accountability with various governments' use of facial recognition technology (FRT) is inexcusable at best. The author states that while facial recognition technology is provably racist, training it on a more diverse set of people would only exacerbate a racist over-policing problem. Do you think facial recognition technology could ever be used safely for good?

## Chapter 4

- Paige Fernandez from the ACLU discussed in a 2021 podcast that the current system of American policing began to “maintain social control of black, enslaved people.” This kind of history is not well known and is rarely taught. What other historical facts or stories do you have about American policing that others are unlikely to know?
- The author quotes Hamid Khan who said “[those using location-based policing] are not there to police potholes and trees. They are there to police people in the location.” What predictive algorithms would you like to see local governments use for social good, such as predicting areas that are prone to potholes?
- A major theme of the chapter is how numbers and statistics can be weaponized against groups of people. This was evidenced by NYPD’s use of CompStat, and again by Karl Pearson’s eugenic motivations for using statistics. How have you seen statistics used to advance societal equity?

## Chapter 5

- EdTech companies have historically had a difficult time raising capital, but this has been changing recently, especially in the last five years. What are examples of companies that are using technology to increase education outcomes, rather than decrease labor costs?
- The author states “one of the big misconceptions of data science is that it provides insights. It doesn’t always.” This is relevant to the tech industry where many companies claim to use data to drive decisions. Have you seen data be misused or creatively interpreted to justify business decisions?

## Chapter 6

- Do you think Attentive is investing enough in making our products accessible?
- The book gives multiple examples of companies taken to court over their products being inaccessible. Do you know of companies that are getting it right, are ahead of the curve, or advocate for accessibility outside of their workplace and products?
- Universities have started adding ethics courses to their computer science curriculums. The author would likely argue that one course is not enough. What other human-centric courses do you think should be required for computer science students?

## Chapter 7

- The Y2GAY problem came about because databases storing personally identifiable information (PII) stored gender information as a boolean. What do you think about websites collecting gender information at all?
  - Where does attentive collect Gender information? How does Attentive (or its clients) use that information? How does Attentive store that information (String, Boolean)?

## Chapter 8

## Chapter 9

## Chapter 10

- As a technologist, would you consider working for the [US Digital Service (USDS)](https://www.usds.gov/ "https://www.usds.gov/") or [18F](https://18f.gsa.gov/ "https://18f.gsa.gov/")? Why or why not?
- The author says one of her default assumptions is that “AI doesn’t work as well as people imagine.” First, what do you think people imagine AI does today? Second, do you agree with the author’s assumption?

## Chapter 11
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTEyNDEyNTI1NzVdfQ==
-->