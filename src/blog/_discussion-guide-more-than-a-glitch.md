---

title: Discussion Guide: More than a Glitch
date: 2025-01-22
tags:
- books

---

A guide with discussion prompts for [Meredeith Broussard's](https://meredithbroussard.com/) [More than a Glitch: Confronting Race, Gender, and Ability Bias in Tech](https://mitpress.mit.edu/9780262548328/more-than-a-glitch/).

I run the engineering book club at my current company, [Attentive](https://www.attentive.com/). For the pace of our book club, we committed to reading 2 chapters every 2 weeks. I personally appreciate having multiple discussions over time, I find I better retain content that way. These are the exact discussion prompts I used over the few months of reading the book, so they're colored by my personal experience and the current culture at Attentive. All prompts are wholly my own and are free to use by all.

## Chapter 1

- Much of the introduction is centered around the word “technochauvinism” and some real-world examples of it. What does the word mean to you, in your own words?

## Chapter 2

- As technologists, do you agree with the author’s explanation of artificial intelligence and machine learning? Do you think there were any consequential details missed?
  - Do you have any ML examples you like to use when talking with non-technologists?
- Do you agree or disagree with this sentence from the book: “whoever owns the [machine learning] model has an enormous amount of power”?
- What do you think are good and just uses for machine learning?

## Chapter 3

- The author tells a story about [Robert Williams](https://www.aclumich.org/en/press-releases/farmington-hills-father-sues-detroit-police-department-wrongful-arrest-based-faulty "https://www.aclumich.org/en/press-releases/farmington-hills-father-sues-detroit-police-department-wrongful-arrest-based-faulty"), a southeast Michigan man who was arrested based on a low-quality surveillance video screenshot and error-prone facial recognition technology (FRT). Many people had the chance to question the algorithm’s “answer” but didn’t. Do you have any personal examples of a decision chain failing you, or regrets of participating in a faulty one?
- Companies that create facial recognition technology (FRT) are incentivized to continually push the adoption of the technology, mostly by government agencies. Customers are incentivized to use the technology as much as possible to justify the cost. Can these incentives ever be aligned to the goal of fair and just policing?
- The lack of audit trails and accountability with various governments' use of facial recognition technology (FRT) is inexcusable at best. The author states that while facial recognition technology is provably racist, training it on a more diverse set of people would only exacerbate a racist over-policing problem. Do you think facial recognition technology could ever be used safely for good?

## Chapter 4

## Chapter 5

## Chapter 6

## Chapter 7

## Chapter 8

## Chapter 9

## Chapter 10

## Chapter 11
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE1NDY1MTkxNDZdfQ==
-->